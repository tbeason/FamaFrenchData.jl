"""
Julia package for easy access to the Ken French Data Library files. See `readFamaFrench`
"""
module FamaFrenchData

using Downloads
using CSV
using ZipFile
using DataFrames
using Scratch
import Dates: now



export readFamaFrench, downloadFamaFrench, listFamaFrench, clearFamaFrenchCache

const KFDLftp = "http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/"

"""
    readFamaFrench(ffn; use_cache=true, cache_max_age=24, kwargs...)

`ffn` can be the table name (in which case it is retreived from the web) or a path to the local file.
`use_cache` controls whether to use cached data (default: true). Cache automatically expires after `cache_max_age` hours (default: 24).
`kwargs` are passed to `CSV.File`. Missing values (`-99.99` or `-999`) are replaced with `missing`.

Returns three pieces:

    - `tables::Vector{DataFrame}` - the extracted tables

    - `tablenotes::Vector{String}` - any notes to the tables

    - `filenotes::String` - notes at the top of the file

Example Usage:

```julia
using DataFrames, FamaFrenchData

# read the Fama-French 3 factors (monthly and annual)
tables, tablenotes, filenotes = readFamaFrench("F-F_Research_Data_Factors")

# read the Fama-French 3 factors (daily)
tablesd, tablenotesd, filenotesd = readFamaFrench("F-F_Research_Data_Factors_Daily")

# read the 25 Size-B/M portfolios (monthly and annual)
tables25, tablenotes25, filenotes25 = readFamaFrench("25_Portfolios_5x5")

# disable caching for a specific call
tables, tablenotes, filenotes = readFamaFrench("F-F_Research_Data_Factors", use_cache=false)

# use cache with 12-hour expiration instead of 24
tables, tablenotes, filenotes = readFamaFrench("F-F_Research_Data_Factors", cache_max_age=12)
```
"""
function readFamaFrench(ffn; use_cache::Bool=true, cache_max_age::Int=24, kwargs...)
    # If ffn is already a file path, use it directly (existing behavior)
    if isfile(ffn)
        ff = open(ffn)
        tables, tablenotes, filenotes = parsefile(ff;kwargs...)
        close(ff)
        return tables, tablenotes, filenotes
    end

    # Check if we should use cache
    cached_path = get_cached_file_path(ffn)
    if use_cache && is_cache_valid(cached_path, cache_max_age)
        # Use cached file
        ff = open(cached_path)
        tables, tablenotes, filenotes = parsefile(ff;kwargs...)
        close(ff)
        return tables, tablenotes, filenotes
    end

    # Download fresh data
    io = IOBuffer()
    Downloads.download(pathtoFamaFrench(ffn), io)
    z = ZipFile.Reader(io)
    ff = first(z.files)

    # Parse the data
    tables, tablenotes, filenotes = parsefile(ff;kwargs...)
    close(ff)

    # Save to cache if caching is enabled
    if use_cache
        # Re-download to cache file (since we already closed the zip reader)
        io2 = IOBuffer()
        Downloads.download(pathtoFamaFrench(ffn), io2)
        z2 = ZipFile.Reader(io2)
        ff2 = first(z2.files)

        # Write to cache file
        open(cached_path, "w") do f
            for line in readlines(ff2)
                println(f, line)
            end
        end
        close(ff2)
    end

    return tables, tablenotes, filenotes
end




"""
    downloadFamaFrench(savename,ffn)

Saves the extracted CSV file from `ffn` to local file `savename`.
"""
function downloadFamaFrench(savename,ffn)
    open(savename,"w") do f
        io = IOBuffer()
        Downloads.download(pathtoFamaFrench(ffn),io)
        z = ZipFile.Reader(io)
        ff = first(z.files)
        for s in readlines(ff)
            println(f,s)
        end
        close(ff)
    end
end




"""
    listFamaFrench(;refresh=false)

Returns a vector of possible table names. Reads from `listFamaFrench.txt`.
When `refresh = true`, first crawls the website to find current list of tables, then overwrites `listFamaFrench.txt` with this list.
The selection of tables is rarely changed, so the provided list is likely sufficient.
"""
function listFamaFrench(;refresh::Bool = false)
    LFF_file = abspath(joinpath(@__DIR__, "..", "listFamaFrench.txt"))
    if refresh
        # grabs filenames from website
        wname  = "https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html" 
        io = IOBuffer()
        Downloads.download(wname,io)
        hs = String(take!(io))
        close(io)
        regx = r"(?<=ftp\/)(.*)(?=_CSV)"
        res=collect(eachmatch(regx,hs)) 
        nms = getfield.(res,:match)
        # writes the available filenames to a file
        rm(LFF_file)
        open(LFF_file,"w") do f
            println(f,"# Generated by FamaFrenchData.jl $(now())")
            for s in nms
                println(f,s)
            end
        end
    else
        nms = readlines(LFF_file)
        popfirst!(nms)
    end

    return nms
end




"""
    clearFamaFrenchCache()

Clears all cached Fama-French data files. Returns the number of files deleted.
"""
function clearFamaFrenchCache()
    cache_dir = get_cache_dir()
    if !isdir(cache_dir)
        return 0
    end
    files = readdir(cache_dir, join=true)
    count = 0
    for f in files
        if isfile(f)
            rm(f)
            count += 1
        end
    end
    return count
end


########################################
# UNEXPORTED FUNCTIONS
########################################

"""
    get_cache_dir()

Returns the scratch space directory for caching Fama-French data files.
Creates the directory if it doesn't exist.
"""
function get_cache_dir()
    cache_dir = @get_scratch!("fama_french_cache")
    return cache_dir
end

"""
    get_cached_file_path(ffn)

Returns the full path to the cached file for a given Fama-French dataset name.
"""
function get_cached_file_path(ffn)
    cache_dir = get_cache_dir()
    # Use a sanitized version of the name for the filename
    safe_name = replace(string(ffn), r"[^a-zA-Z0-9_-]" => "_")
    return joinpath(cache_dir, safe_name * ".csv")
end

"""
    is_cache_valid(filepath, max_age_hours=24)

Checks if a cached file exists and is younger than max_age_hours.
Returns true if cache is valid, false otherwise.
"""
function is_cache_valid(filepath, max_age_hours=24)
    if !isfile(filepath)
        return false
    end

    # Check file modification time
    file_mtime = stat(filepath).mtime
    current_time = time()
    age_hours = (current_time - file_mtime) / 3600

    return age_hours < max_age_hours
end
"""
    parsefile(lines;kwargs...)

The workhorse function behind `readFamaFrench`.

`lines` is an `IO`.
`kwargs` are passed to `CSV.File`. Missing values (`-99.99` or `-999`) are replaced with `missing`.

Returns three pieces:

    - `tables::Vector{DataFrame}` - the extracted tables

    - `tablenotes::Vector{String}` - any notes to the 
    
    - `filenotes::String` - notes at the top of the file
"""
function parsefile(lines;kwargs...)
    csvopt = (missingstring = ["-99.99","-999"],normalizenames = false,kwargs...)

    stringarray = readlines(lines,keep=true)
    striparray = strip.(stringarray)
    splits = split.(stringarray,",")
    ncols = length.(splits)

    tranges = contiguousblocks(ncols)
    ntables = length(tranges)

    allempty = findall(isempty,striparray)
    lastempty = [lastornothing(filter(x -> x < k,allempty)) for k in first.(tranges)]
    nameranges = [isnothing(lastempty[i]) ? nothing : range(lastempty[i],first(tranges[i])-1,step=1) for i in 1:ntables] 

    dfvec = Vector{DataFrame}(undef,ntables)
    for i in 1:ntables
        ios = IOBuffer(string(stringarray[tranges[i]]...))
        dfvec[i] = CSV.read(ios,DataFrame;csvopt...)
        rename!(dfvec[i],Symbol(first(names(dfvec[i]))) => :Date)
        close(ios)
    end
    if isnothing(first(nameranges))
        notestop = tranges[1][1]-1
        tablenotes = [i==1 ? "" : strip_rn(string(striparray[nameranges[i]]...)) for i in 1:ntables]
    else
        tablenotes = [strip_rn(string(striparray[nameranges[i]]...)) for i in 1:ntables]
        notestop = first(lastempty)
    end
    filenotes = strip_rn(string(lines.name,"  ",strip.(stringarray[1:notestop])...))

    return dfvec,tablenotes,filenotes
end


strip_rn(s) = foldl(replace,["\r"=>"", "\n"=>" "],init=s)



"""
    contiguousblocks(x)

Takes in a vector of `Int` and returns the portions containing contiguous blocks (sequences that increase by 1).

Requires a sequence to have length 3 or greater.
"""
function contiguousblocks(x::AbstractVector{T}) where {T}
    M = maximum(x)
    L = length(x)
    tranges = Vector{UnitRange{Int64}}(undef,0)
    for i in 2:M
        tmpi = findall(==(i),x)
        isempty(tmpi) && continue
        starti = tmpi[1]
        lasti = tmpi[1]
        for (j,n) in enumerate(tmpi)
            j==1 && continue
            distance = n-lasti
            if distance==1
                lasti = n
                if j==length(tmpi)
                    R = starti:lasti
                    # println(R)
                    length(R)>=3 && push!(tranges,R)
                end
                continue
            else
                R = starti:lasti
                # println(R)
                length(R)>=3 && push!(tranges,R)
                starti = n
                lasti = n
            end
        end

    end
    return tranges
end



"""
    pathtoFamaFrench(ffn)

Generates the full web path to the file.
"""
pathtoFamaFrench(ffn) = joinpath(KFDLftp,string(ffn, "_CSV.zip"))




"""
    lastornothing(x) = isempty(x) ? nothing : last(x)

A helper function.
"""
lastornothing(x) = isempty(x) ? nothing : last(x)



end # module
